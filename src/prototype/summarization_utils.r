# Functions useful for summarization of data generated by 
# Can_Cenik_lab.Ian_Hoskins.bioinfo.analysis.variant_caller.VariantCaller

library(data.table)
library(e1071)

VCF_SUMMARY_V0.2_COLCLASSES = c("#CHROM"="character", "POS"="integer", "ID"="character", "REF"="character", "ALT"="character", "QUAL"="numeric", "FILTER"="character", 
                                 "DP"="integer", "AO"="integer", "AD"="integer", "CAO"="integer", "CR"="numeric", "CDR"="numeric", "AF"="numeric", "CF"="numeric", 
                                 "NORM_AO"="numeric", "NORM_CAO"="numeric", "R1_AO"="integer", "R2_AO"="integer", "R1_MOD_RP"="numeric", "R1_MED_RP"="numeric", 
                                 "R2_MOD_RP"="numeric", "R2_MED_RP"="numeric", "R1_MOD_BQ"="numeric", "R1_MED_BQ"="numeric", "R2_MOD_BQ"="numeric", "R2_MED_BQ"="numeric", 
                                 "R1_MOD_NM"="numeric", "R1_MED_NM"="numeric", "R2_MOD_NM"="numeric", "R2_MED_NM"="numeric", "POS_NT"="integer", 
                                 "REF_NT"="character", "ALT_NT"="character", "EXON_ID"="factor", "LOCATION"="character", "REF_CODON"="character", "ALT_CODON"="character",
                                 "REF_AA"="character", "ALT_AA"="character", "AAM_AA_CHANGE"="character", "AAM_AA_POS"="character", "POPCODE_NNK_SIGNATURE"="logical",
                                 "AAM_AA_MOTIFS"="character", "AAM_AA_MOTIF_POS"="character", "AAM_F1_STOPS"="integer", "AAM_F1_STOP_POS"="character", 
                                 "AAM_F2_STOPS"="integer", "AAM_F2_STOP_POS"="character",  "AAM_F3_STOPS"="integer", "AAM_F3_STOP_POS"="character", 
                                 "AAM_AROMATICITY"="numeric", "AAM_GRAVY"="numeric", "AAM_INSTABILITY"="numeric", "AAM_ISOELECTRIC_POINT"="numeric")


VCF_SUMMARY_V0.3_COLCLASSES = c("#CHROM"="character", "POS"="integer", "ID"="character", "REF"="character", "ALT"="character", "QUAL"="numeric", "FILTER"="character", 
                                "POS_NT"="integer", "REF_NT"="character", "ALT_NT"="character", "DP"="integer", "CAO"="integer", "NORM_CAO"="numeric", "CAF"="numeric",
                                "R1_PLUS_AO"="integer", "R1_MINUS_AO"="integer", "R2_PLUS_AO"="integer", "R2_MINUS_AO"="integer",
                                "R1_PLUS_MED_RP"="numeric", "R1_MINUS_MED_RP"="numeric", "R2_PLUS_MED_RP"="numeric", "R2_MINUS_MED_RP"="numeric",
                                "R1_PLUS_MED_BQ"="numeric", "R1_MINUS_MED_BQ"="numeric", "R2_PLUS_MED_BQ"="numeric", "R2_MINUS_MED_BQ"="numeric",
                                "R1_PLUS_MED_NM"="numeric", "R1_MINUS_MED_NM"="numeric", "R2_PLUS_MED_NM"="numeric", "R2_MINUS_MED_NM"="numeric",
                                "EXON_ID"="factor", "LOCATION"="character", "REF_CODON"="character", "ALT_CODON"="character", "REF_AA"="character", "ALT_AA"="character", 
                                "AAM_AA_CHANGE"="character", "AAM_AA_POS"="character", "POPCODE_NNK_SIGNATURE"="logical", "AAM_AA_MOTIFS"="character", "AAM_AA_MOTIF_POS"="character",
                                "AAM_F1_STOPS"="integer", "AAM_F1_STOP_POS"="character", "AAM_F2_STOPS"="integer", "AAM_F2_STOP_POS"="character", 
                                "AAM_F3_STOPS"="integer", "AAM_F3_STOP_POS"="character", "AAM_AROMATICITY"="numeric", "AAM_GRAVY"="numeric", 
                                "AAM_INSTABILITY"="numeric", "AAM_ISOELECTRIC_POINT"="numeric")

# Added Kozak motifs and nucleotide statistics
VCF_SUMMARY_V0.5_COLCLASSES = c("#CHROM"="character", "POS"="integer", "ID"="character", "REF"="character", "ALT"="character", "QUAL"="numeric", "FILTER"="character", 
                                "POS_NT"="integer", "REF_NT"="character", "ALT_NT"="character", "DP"="integer", "CAO"="integer", "NORM_CAO"="numeric", "CAF"="numeric",
                                "R1_PLUS_AO"="integer", "R1_MINUS_AO"="integer", "R2_PLUS_AO"="integer", "R2_MINUS_AO"="integer",
                                "R1_PLUS_MED_RP"="numeric", "R1_MINUS_MED_RP"="numeric", "R2_PLUS_MED_RP"="numeric", "R2_MINUS_MED_RP"="numeric",
                                "R1_PLUS_MED_BQ"="numeric", "R1_MINUS_MED_BQ"="numeric", "R2_PLUS_MED_BQ"="numeric", "R2_MINUS_MED_BQ"="numeric",
                                "R1_PLUS_MED_NM"="numeric", "R1_MINUS_MED_NM"="numeric", "R2_PLUS_MED_NM"="numeric", "R2_MINUS_MED_NM"="numeric",
                                "EXON_ID"="factor", "LOCATION"="character", "REF_CODON"="character", "ALT_CODON"="character", "REF_AA"="character", "ALT_AA"="character", 
                                "AAM_AA_CHANGE"="character", "AAM_AA_POS"="character", "POPCODE_NNK_SIGNATURE"="logical", 
                                "AAM_KOZAK_MOTIFS"="character", "AAM_KOZAK_MOTIF_POS"="character","AAM_AA_MOTIFS"="character", "AAM_AA_MOTIF_POS"="character",
                                "AAM_F1_STOPS"="integer", "AAM_F1_STOP_POS"="character", "AAM_F2_STOPS"="integer", "AAM_F2_STOP_POS"="character", 
                                "AAM_F3_STOPS"="integer", "AAM_F3_STOP_POS"="character", "AAM_AROMATICITY"="numeric", "AAM_GRAVY"="numeric", 
                                "AAM_INSTABILITY"="numeric", "AAM_ISOELECTRIC_POINT"="numeric", "AAM_GC_CONTENT"="numeric", "AAM_SHANNON_INDEX"="numeric", 
                                "AAM_MIN_DELTA_DELTA_G"="numeric", "AAM_MED_DELTA_DELTA_G"="numeric")

VCF_SUMMARY_V0.4_COLCLASSES = copy(VCF_SUMMARY_V0.3_COLCLASSES)
VCF_SUMMARY_V0.6_COLCLASSES = copy(VCF_SUMMARY_V0.5_COLCLASSES)
VCF_SUMMARY_V0.7_COLCLASSES = copy(VCF_SUMMARY_V0.5_COLCLASSES)
VCF_SUMMARY_V0.8_COLCLASSES = c("#CHROM"="character", "POS"="integer", "ID"="character", "REF"="character", "ALT"="character", "QUAL"="numeric", "FILTER"="character", 
                                "POS_NT"="integer", "REF_NT"="character", "ALT_NT"="character", "DP"="integer", "CAO"="integer", "NORM_CAO"="numeric", "CAF"="numeric",
                                "R1_PLUS_AO"="integer", "R1_MINUS_AO"="integer", "R2_PLUS_AO"="integer", "R2_MINUS_AO"="integer",
                                "R1_PLUS_MED_RP"="numeric", "R1_MINUS_MED_RP"="numeric", "R2_PLUS_MED_RP"="numeric", "R2_MINUS_MED_RP"="numeric",
                                "R1_PLUS_MED_BQ"="numeric", "R1_MINUS_MED_BQ"="numeric", "R2_PLUS_MED_BQ"="numeric", "R2_MINUS_MED_BQ"="numeric",
                                "R1_PLUS_MED_NM"="numeric", "R1_MINUS_MED_NM"="numeric", "R2_PLUS_MED_NM"="numeric", "R2_MINUS_MED_NM"="numeric",
                                "EXON_ID"="factor", "LOCATION"="character", "REF_CODON"="character", "ALT_CODON"="character", "REF_AA"="character", "ALT_AA"="character", 
                                "AAM_AA_CHANGE"="character", "AAM_AA_POS"="character", "POPCODE_NNK_SIGNATURE"="logical", 
                                "AAM_KOZAK_MOTIFS"="character", "AAM_KOZAK_MOTIF_POS"="character","AAM_AA_MOTIFS"="character", "AAM_AA_MOTIF_POS"="character",
                                "AAM_F1_STOPS"="integer", "AAM_F2_STOPS"="integer", "AAM_F3_STOPS"="integer", "AAM_AROMATICITY"="numeric", "AAM_GRAVY"="numeric", 
                                "AAM_INSTABILITY"="numeric", "AAM_ISOELECTRIC_POINT"="numeric", "AAM_GC_CONTENT"="numeric", "AAM_SHANNON_INDEX"="numeric", 
                                "AAM_MIN_DELTA_DELTA_G"="numeric")

VCF_SUMMARY_V0.9_COLCLASSES = copy(VCF_SUMMARY_V0.8_COLCLASSES)

VCF_SUMMARY_V0.2_NONSCALE_FEATURES = c("R1_MOD_RP", "R1_MED_RP", "R2_MOD_RP", "R2_MED_RP", 
                                       "R1_MOD_BQ", "R1_MED_BQ", "R2_MOD_BQ", "R2_MED_BQ", 
                                       "R1_MOD_NM", "R1_MED_NM", "R2_MOD_NM", "R2_MED_NM",
                                       "AAM_F1_STOPS", "AAM_F2_STOPS", "AAM_F3_STOPS", 
                                       "AAM_AA_MOTIF_COUNT")

VCF_SUMMARY_V0.3_NONSCALE_FEATURES = c("AAM_F1_STOPS", "AAM_F2_STOPS", "AAM_F3_STOPS", "AAM_AA_MOTIF_COUNT")
VCF_SUMMARY_V0.4_NONSCALE_FEATURES = copy(VCF_SUMMARY_V0.3_NONSCALE_FEATURES)

VCF_SUMMARY_V0.5_NONSCALE_FEATURES = append(copy(VCF_SUMMARY_V0.3_NONSCALE_FEATURES), 
                                            c("AAM_GC_CONTENT", "AAM_SHANNON_INDEX", 
                                              "AAM_MIN_DELTA_DELTA_G", "AAM_MED_DELTA_DELTA_G"))
VCF_SUMMARY_V0.6_NONSCALE_FEATURES = copy(VCF_SUMMARY_V0.5_NONSCALE_FEATURES)
VCF_SUMMARY_V0.7_NONSCALE_FEATURES = copy(VCF_SUMMARY_V0.5_NONSCALE_FEATURES)

VCF_SUMMARY_V0.8_NONSCALE_FEATURES = append(copy(VCF_SUMMARY_V0.3_NONSCALE_FEATURES), 
                                            c("AAM_GC_CONTENT", "AAM_SHANNON_INDEX", "AAM_MIN_DELTA_DELTA_G"))

VCF_SUMMARY_V0.9_NONSCALE_FEATURES = copy(VCF_SUMMARY_V0.8_NONSCALE_FEATURES)

VCF_SUMMARY_V0.4_RLS_ANNOT_FEATURES = c(
  "TYPE", "TILE", "VAR_TYPE", "POS", "REF", "ALT", "UP_REF_NT", "DOWN_REF_NT", 
  "REF_CODON", "ALT_CODON", "REF_AA", "AAM_AA_POS", "ALT_AA", 
  "AAM_AA_CHANGE", "AAM_AA_MOTIFS", "AAM_F1_STOPS", "AAM_F2_STOPS", "AAM_F3_STOPS", 
  "AAM_AROMATICITY", "AAM_GRAVY", "AAM_INSTABILITY", "AAM_ISOELECTRIC_POINT", "AAM_AA_MOTIF_COUNT")

VCF_SUMMARY_V0.5_RLS_ANNOT_FEATURES = c(
  "TYPE", "TILE", "VAR_TYPE", "POS", "REF", "ALT",  "UP_REF_NT", "DOWN_REF_NT", 
  "REF_CODON", "ALT_CODON", "REF_AA", "AAM_AA_POS", "ALT_AA", 
  "AAM_AA_CHANGE", "AAM_AA_MOTIFS", "AAM_F1_STOPS", "AAM_F2_STOPS", "AAM_F3_STOPS", 
  "AAM_AROMATICITY", "AAM_GRAVY", "AAM_INSTABILITY", "AAM_ISOELECTRIC_POINT", 
  "AAM_AA_MOTIF_COUNT", "AAM_GC_CONTENT", "AAM_SHANNON_INDEX", 
  "AAM_MIN_DELTA_DELTA_G")

VCF_SUMMARY_V0.6_RLS_ANNOT_FEATURES = copy(VCF_SUMMARY_V0.5_RLS_ANNOT_FEATURES)
VCF_SUMMARY_V0.7_RLS_ANNOT_FEATURES = copy(VCF_SUMMARY_V0.5_RLS_ANNOT_FEATURES)

# Removed AAM stop positions and median delta G stats
VCF_SUMMARY_V0.8_RLS_ANNOT_FEATURES = c(
  "TYPE", "TILE", "VAR_TYPE", "POS", "REF", "ALT",  "UP_REF_NT", "DOWN_REF_NT", 
  "REF_CODON", "ALT_CODON", "REF_AA", "AAM_AA_POS", "ALT_AA", 
  "AAM_AA_CHANGE", "AAM_AA_MOTIFS", "AAM_F1_STOPS", "AAM_F2_STOPS", "AAM_F3_STOPS", 
  "AAM_AROMATICITY", "AAM_GRAVY", "AAM_INSTABILITY", "AAM_ISOELECTRIC_POINT", 
  "AAM_AA_MOTIF_COUNT", "AAM_GC_CONTENT", "AAM_SHANNON_INDEX")

VCF_SUMMARY_V0.9_RLS_ANNOT_FEATURES = copy(VCF_SUMMARY_V0.8_RLS_ANNOT_FEATURES)

VCF_SUMMARY_V0.2_FEATURES_CORRECT = c("R1_AO", "R2_AO", "AO", "CAO", "NORM_AO", "NORM_CAO")
VCF_SUMMARY_V0.3_FEATURES_CORRECT = c("R1_PLUS_AO", "R2_PLUS_AO", "R1_MINUS_AO", "R2_MINUS_AO", "CAO", "NORM_CAO")
VCF_SUMMARY_V0.4_FEATURES_CORRECT = copy(VCF_SUMMARY_V0.3_FEATURES_CORRECT)
VCF_SUMMARY_V0.5_FEATURES_CORRECT = copy(VCF_SUMMARY_V0.3_FEATURES_CORRECT)
VCF_SUMMARY_V0.6_FEATURES_CORRECT = copy(VCF_SUMMARY_V0.3_FEATURES_CORRECT)
VCF_SUMMARY_V0.7_FEATURES_CORRECT = copy(VCF_SUMMARY_V0.3_FEATURES_CORRECT)
VCF_SUMMARY_V0.8_FEATURES_CORRECT = copy(VCF_SUMMARY_V0.3_FEATURES_CORRECT)
VCF_SUMMARY_V0.9_FEATURES_CORRECT = copy(VCF_SUMMARY_V0.3_FEATURES_CORRECT)

AA_CODONS_LIST<- list("A"=c("GCC", "GCT", "GCA", "GCG"), "C"=c("TGC", "TGT"), "D"=c("GAC", "GAT"), "E"=c("GAG", "GAA"), "F"=c("TTC", "TTT"), 
                 "G"=c("GGC", "GGG", "GGA", "GGT"), "H"=c("CAC", "CAT"), "I"=c("ATC", "ATT", "ATA"), "K"=c("AAG", "AAA"), 
                 "L"=c("CTG", "CTC", "TTG", "CTT", "CTA", "TTA"), "M"=c("ATG"), "N"=c("AAC", "AAT"), 
                 "P"=c("CCC", "CCT", "CCA", "CCG"), "Q"=c("CAG", "CAA"), "R"=c("CGC", "AGG", "CGG", "AGA", "CGA", "CGT"), 
                 "S"=c("AGC", "TCC", "TCT", "AGT", "TCA", "TCG"), "T"=c("ACC", "ACA", "ACT", "ACG"), "V"=c("GTG", "GTC", "GTT", "GTA"), 
                 "W"=c("TGG"), "Y"=c("TAC", "TAT"), "*"=c("TGA", "TAG", "TAA"))

STOP_CODONS<- c("TGA", "TAG", "TAA")

aa_codon_counts<- sapply(AA_CODONS_LIST, length)

aa_codon_proportions<- aa_codon_counts/sum(aa_codon_counts)

positive_charged_aas<- c("R", "H", "K")
negative_charged_aas<- c("D", "E")
polar_uncharged_aas<- c("S", "T", "N", "Q", "C")
nonpolar_uncharged_aas<- c("A", "V", "I", "L", "M", "F", "Y", "W", "G", "P")
other_aas<- c("C", "G", "P")

aa_map<- list("A"="Ala", "C"="Cys", "D"="Asp", "E"="Glu", "F"="Phe", 
              "G"="Gly", "H"="His", "I"="Ile", "K"="Lys", "L"="Leu", 
              "M"="Met", "N"="Asn", "P"="Pro", "Q"="Gln", "R"="Arg", 
              "S"="Ser", "T"="Thr", "V"="Val", "W"="Trp", "Y"="Tyr",
              "*"="Ter")

get_aa_change_type<- function(x){
  
  if(x%in%positive_charged_aas){
    return("Positive")
  } else if(x%in%negative_charged_aas){
    return("Negative")
  } else if(x%in%polar_uncharged_aas){
    return("Polar")
  }else if(x%in%nonpolar_uncharged_aas){
    return("Nonpolar")
  } else{
    return("Other")
  }
}

aa_class_list<- list("Positive_charged"=positive_charged_aas, "Negative_charged"=negative_charged_aas, 
                     "Polar_uncharged"=polar_uncharged_aas, "Nonpolar_uncharged"=nonpolar_uncharged_aas, 
                     "Other"=other_aas, "Stop"=c("*"))

positive_charged_codons<- c("CGC", "AGG", "CGG", "AGA", "CGA", "CGT",   "CAC", "CAT",   "AAG", "AAA")
negative_charged_codons<- c("GAC", "GAT",   "GAG", "GAA")
polar_uncharged_codons<- c("AGC", "TCC", "TCT", "AGT", "TCA", "TCG",   "ACC", "ACA", "ACT", "ACG",   "AAC", "AAT",   "CAG", "CAA")
nonpolar_uncharged_codons<- c("GCC", "GCT", "GCA", "GCG",   "GTG", "GTC", "GTT", "GTA",   "ATC", "ATT", "ATA",   
                              "CTG", "CTC", "TTG", "CTT", "CTA", "TTA",   "ATG",   "TTC", "TTT",   "TAC", "TAT",   "TGG")

binding_motifs<- c("Puf3"="TGTAAATA", "Whi3"="TGCAT", "polyU"="TTTTTTA", "OSPHOS"="ATATTC")

#' Reads in variant calls in vcf.summary.txt format
#'
#' @param indir character path of input directory
#' @return data.table of all samples in the input dir
read_vcf_summary_files<- function(indir=".", colclasses=VCF_SUMMARY_V0.9_COLCLASSES){
  
  vcf_summary_file_pattern<- "reference.variant.candidates.vcf.summary.txt"
  vcf_summary_files<- dir(path=indir, pattern=vcf_summary_file_pattern, full.names=TRUE)
  
  if(length(vcf_summary_files)==0){
    stop(paste("No reference.variant.candidates.vcf.summary.txt files found in directory", vcf_summary_file_pattern))
  }
         
  vcf_summary_files_split<- sapply(strsplit(as.character(vcf_summary_files), "/", fixed=TRUE), tail, 1)
  sample_vector<- sapply(strsplit(as.character(vcf_summary_files_split), ".", fixed=TRUE), head, 1)
  
  vcf_summary_file_list<- lapply(vcf_summary_files, fread, sep="\t", header=TRUE, colClasses=colclasses)
  vcf_summary_file_list_nrows<- sapply(vcf_summary_file_list, nrow)
  
  # Run with fill=TRUE just in case any files differ in the number of columns
  vcf_summary_file_list_all<- rbindlist(vcf_summary_file_list, fill=TRUE)
  vcf_summary_file_list_all[,Sample:=factor(rep(sample_vector, vcf_summary_file_list_nrows), levels=sample_vector)]
  return(vcf_summary_file_list_all)
}


#' Gets a data.table matching coordinate positions to PCR tile
#'
#' @param design_version character one of v0.1 or v0.2, specifying CBS primer tile design version
#' @return data.table with POS and TILE columns
get_tile_position_dt<- function(design_version="v0.1"){

  # Manually-curated 1-based start and stop positions for each tile across CBS
  # tile-seq designs
  tile_positions<- list(TILE_1=seq(244,368), TILE_2=seq(369,470), TILE_3=seq(471,584), TILE_4=seq(585,698), TILE_5=seq(699,812), 
                        TILE_6=seq(813,926), TILE_7=seq(927,1034), TILE_8=seq(1035,1148), TILE_9=seq(1149,1262), TILE_10=seq(1263,1376), 
                        TILE_11=seq(1377,1490), TILE_12=seq(1491,1604), TILE_13=seq(1605,1715), TILE_14=seq(1716,1823), TILE_15=seq(1824,1971))
  
  # ArcherDX AMP designs
  if(design_version=="v0.2"){
    tile_positions<- list(TILE_1=seq(244,368), TILE_2=seq(369,467), TILE_3=seq(468,584), TILE_4=seq(585,698), TILE_5=seq(699,815), 
                          TILE_6=seq(806,921), TILE_7=seq(922,1029), TILE_8=seq(1030,1148), TILE_9=seq(1149,1263), TILE_10=seq(1264,1382), 
                          TILE_11=seq(1383,1485), TILE_12=seq(1486,1596), TILE_13=seq(1597,1715), TILE_14=seq(1716,1823), TILE_15=seq(1824,1971))
  }
  
  tile_labels<- names(tile_positions)
  
  tile_positions_lengths<- sapply(tile_positions, length)
  
  tile_positions_dt<- data.table(POS=unlist(tile_positions), TILE=as.factor(rep(tile_labels, tile_positions_lengths)))
  
  return(tile_positions_dt)
}


#' Gets the type of variant given a VCF REF and ALT field
#'
#' @param ref character REF
#' @param alt character ALT
#' @return character one of {"SNP", "di_nt_MNP", "tri_nt_MNP", "MNP", "[123456]_nt_HAPLO", "INS", "DEL"}
get_var_type<- function(ref, alt, split_mnps=TRUE){
  
  len_ref<- nchar(ref)
  len_alt<- nchar(alt)
  ref_c<- unlist(strsplit(ref, ""))
  alt_c<- unlist(strsplit(alt, ""))
  
  if(len_ref == len_alt){
    if(len_ref == 1){
      return("SNP")
      }
    else if(split_mnps) {
      if(len_ref == 2){
        return("di_nt_MNP")
      }
      hd<- hamming.distance(ref_c, alt_c)
      if(len_ref == 3){
        if(hd == 2){
          return("di_nt_MNP")
        } else {
          return("tri_nt_MNP")
        }
      } else {
        if(hd == 2){
          return("2_nt_HAPLO")
        } else if (hd == 3){
          return("3_nt_HAPLO")
        } else if (hd == 4){
          return("4_nt_HAPLO")
        } else if (hd == 5){
          return("5_nt_HAPLO")
        } else if (hd == 6){
          return("6_nt_HAPLO")
        }
      }
    } else{
    return("MNP")
    }
  } else if(len_ref < len_alt){
    return("INS")
  } else if(len_ref > len_alt){
    return("DEL")
  }
}



#' Adds a fraction ID to alias sample name
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param mapping_dt data.table mapping sample name to desired fraction label
#' @param as_int leave the fractions as integers?
#' @return data.table annotated with Fraction column
add_fraction_ids<- function(in_dt, mapping_dt, endo_fraction=10, as_int=TRUE){
  
  copy_dt<- copy(in_dt)
  sample_matches<- match(in_dt$Sample, mapping_dt$Sample)
  copy_dt[,Fraction:=mapping_dt[sample_matches, Fraction]]
  
  if(as_int){
    return(copy_dt)
  }
  
  # Need to add character to int column, so first change to factor
  copy_dt[,Fraction:=as.factor(Fraction)]
  copy_dt[Fraction==as.character(endo_fraction), Fraction:="Endo"]
  copy_dt[,Fraction:=factor(Fraction)]
  return(copy_dt)
}


#' Adds a fraction labels to alias fraction number
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param mapping_dt data.table mapping sample name to desired fraction label
#' @return data.table annotated with Fraction column
add_fraction_labels<- function(in_dt, mapping_dt){
  
  copy_dt<- copy(in_dt)
  sample_matches<- match(in_dt$Fraction, mapping_dt$Fraction)
  copy_dt[,Fraction_label:=mapping_dt[sample_matches, Fraction_label]]
  copy_dt[,Fraction_label:=as.factor(Fraction_label)]
  return(copy_dt)
}


#' Annotates data.table of vcf.summary.txt formatted data
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param mapping_dt data.table mapping sample name to desired fraction label
#' @param tile_positions data.table with POS and TILE columns, for annotating PCR tiles
#'   NULL if no tile annotation desired.
#' @return data.table of all samples in the input directory.
annotate_calls<- function(in_dt, mapping_dt=NULL, tile_positions_dt=NULL){
  
  copy_dt<- copy(in_dt)
  
  copy_dt[,VAR_ID:=as.factor(paste(`#CHROM`,POS,REF,ALT,sep=":"))]
  
  if(!is.null(tile_positions_dt)){
    tile_positions_match<- match(copy_dt$POS, tile_positions_dt$POS)
    copy_dt[,TILE:=as.factor(tile_positions_dt[tile_positions_match,TILE])]
  }
  
  copy_dt[,TYPE:=get_var_type(REF, ALT), by=seq_len(nrow(copy_dt))]
  copy_dt[,SUBST:=as.factor(paste(REF_NT, ALT_NT, sep=":"))]
  
  copy_dt[,AAM_AA_MOTIF_COUNT:=length(unlist(strsplit(AAM_AA_MOTIFS, ","))), 
          by=seq_len(nrow(copy_dt))]
  
  copy_dt[,TYPE:=as.factor(TYPE)]
  copy_dt[,REF_NT:=as.factor(REF_NT)]
  copy_dt[,ALT_NT:=as.factor(ALT_NT)]
  copy_dt[,EXON_ID:=as.factor(EXON_ID)]
  copy_dt[,`#CHROM`:=as.factor(`#CHROM`)]
  copy_dt[,FILTER:=as.factor(FILTER)]
  copy_dt[,UP_REF_NT:=as.factor(UP_REF_NT)]
  copy_dt[,DOWN_REF_NT:=as.factor(DOWN_REF_NT)]
  copy_dt[,AAM_AA_POS2:=as.numeric(sapply(
    as.character(AAM_AA_POS), summarize_str_list)),
          by=seq_len(nrow(copy_dt))]
  
  copy_dt[, VAR_TYPE:=ifelse(REF_AA==ALT_AA, "Silent", "Missense"), 
          by=seq_len(nrow(copy_dt))]
  
  copy_dt[ALT_AA=="*", VAR_TYPE:="Nonsense"]
  copy_dt[,VAR_TYPE:=factor(VAR_TYPE, levels=c("Silent", "Missense", "Nonsense"))]
  
  if(!is.null(mapping_dt)){
    copy_dt<- add_fraction_ids(copy_dt, mapping_dt)
  }
  
  copy_dt[,log10_CAF:=log10(CAF)]
  
  return(copy_dt)
}


#' Summarizes counts of unique variants and AA changes for each sample
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @return data.table of counts for variants and AA changes, by each variant type
summarize_counts<- function(in_dt){
  
  calls_by_sample<- in_dt[,length(unique(VAR_ID)),by=.(Sample)]
  calls_by_sample$SNPs<- in_dt[nchar(REF)==1,length(unique(VAR_ID)),by=.(Sample)]$V1
  calls_by_sample$MNPs<- in_dt[nchar(REF)>1,length(unique(VAR_ID)),by=.(Sample)]$V1
  
  # This is not necessarily accurate for di-nts and comparison to theoretical increase of variants from SNP to (SNP + di-nt MNP)
  calls_by_sample$di_nt_MNPs<- in_dt[TYPE=="di_nt_MNP", length(unique(VAR_ID)),by=.(Sample)]$V1
  
  # by virtue of the above point, this could have di-nt MNPs in it as well
  calls_by_sample$tri_nt_MNPs<- in_dt[TYPE=="tri_nt_MNP", length(unique(VAR_ID)),by=.(Sample)]$V1
  
  # Multi-AA changes are separated and each AA change called unique
  # At some point we may actually want to consider them different
  calls_by_sample$AA_changes<- in_dt[,length(unique(unlist(strsplit(AAM_AA_CHANGE, ",")))),by=.(Sample)]$V1
  calls_by_sample$AA_changes_SNPs<- in_dt[nchar(REF)==1, length(unique(unlist(strsplit(AAM_AA_CHANGE, ",")))),by=.(Sample)]$V1
  calls_by_sample$AA_changes_MNPs<- in_dt[nchar(REF)>1, length(unique(unlist(strsplit(AAM_AA_CHANGE, ",")))),by=.(Sample)]$V1
  
  # If the variants are off, so are the AA changes
  calls_by_sample$AA_changes_di_nt_MNPs<- in_dt[TYPE=="di_nt_MNP", length(unique(unlist(strsplit(AAM_AA_CHANGE, ",")))),by=.(Sample)]$V1
  calls_by_sample$AA_changes_tri_nt_MNPs<- in_dt[TYPE=="tri_nt_MNP", length(unique(unlist(strsplit(AAM_AA_CHANGE, ",")))),by=.(Sample)]$V1
  
  names(calls_by_sample)<- c("Sample", "Variant_calls", "Variant_calls_SNPs", "Variant_calls_MNPs", "Variant_calls_di_nt_MNPs", "Variant_calls_tri_nt_MNPs",
                             "AA_changes", "AA_changes_SNPs", "AA_changes_MNPs", "AA_changes_di_nt_MNPs", "AA_changes_tri_nt_MNPs")
  
  return(calls_by_sample)
}


#' Melts the summarized counts generated from summarize_counts()
#'
#' @param calls_by_sample data.table of variant and AA change calls for each sample
#' @param character id_vars variables to keep as IDs
#' @return data.table of melted counts
melt_summarized_counts<- function(calls_by_sample, id_vars=c("Sample")){
  calls_by_sample_melt<- melt(calls_by_sample, id.vars=id_vars, variable.name="Statistic", value.name="Count")
  nrows<- nrow(calls_by_sample_melt)
  calls_by_sample_melt[,Metric:=as.factor(rep(c("Variant_calls", "AA_changes"), each=nrows/2))]
  return(calls_by_sample_melt)
}


#' Generates a basic clustered heatmap
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param var1 character of x axis variable
#' @param var2 character of y axis variable
#' @param fill_var character of a numeric variable to use for fill color
#' @param na_val numeric or integer value to use for NA values
#' @param transform_fun character name of a transformation function for the fill_var
plot_heatmap<- function(in_dt, var1="AAM_AA_CHANGE", var2="Fraction", fill_var="NORM_CAO", na_val=0.1, 
                        transform_fun="log2", agg_fun="median", scale_spec="row"){
  
  library(gplots)
  library(RColorBrewer)
  
  cast_formula<- as.formula(paste0(var1, " ~ ", var2))
  
  # First create a matrix of the data to be plotted
  heatmap_in<- dcast(in_dt, cast_formula, value.var=fill_var, fun.aggregate=get(agg_fun))
  
  heatmap_in_rownames<- heatmap_in[,var1,with=FALSE][[1]]
  heatmap_in<- heatmap_in[,-..var1]
  heatmap_in<- as.matrix(heatmap_in, rownames.value=heatmap_in_rownames)
  
  heatmap_in_nas<- is.na(heatmap_in)
  heatmap_in[heatmap_in_nas]<- na_val

  heatmap_in_final<- t(get(transform_fun)(heatmap_in))
  
  my_palette<- colorRampPalette(brewer.pal(9, "PuRd"))(n=100)
  
  heatmap.2(heatmap_in_final, trace="none", scale=scale_spec, col=my_palette, 
            symkey=FALSE, keysize=1, cexRow=1, srtRow=0,
            key.title=paste0(transform_fun, "(", fill_var, ")"), xlab=var1, ylab=var2)
  
  return(heatmap_in_final)
}


#' Combines mutant fractions by aggregating numeric values
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param agg_fun function to use to aggregate for each (VAR_ID, POS_NT) level
combine_fractions<- function(in_dt,  agg_fun=mean){
  
  dt_copy<- copy(in_dt)
  dt_copy[,`:=`(POS=as.factor(POS), VAR_ID=as.factor(VAR_ID), 
                POS_NT=as.factor(POS_NT), EXON_ID=as.factor(EXON_ID))]
  
  # Remove the negative control sample, which should have Fraction==NA
  dt_copy<- dt_copy[!is.na(Fraction),]
  
  # Do away with the columns since we are combining now
  dt_copy[,Sample:=NULL]
  dt_copy[,Fraction:=NULL]
  
  dt_keys<- c("VAR_ID", "POS_NT")
  
  numeric_col_classes<- sapply(dt_copy, class)
  which_numeric<- numeric_col_classes%in%c("integer", "numeric", "single", "double")
  
  numeric_cols_dt<- dt_copy[,which_numeric,with=FALSE]
  nonnumeric_cols_dt<- dt_copy[,!which_numeric,with=FALSE]
  
  collapse_nonnumeric_dt<- nonnumeric_cols_dt[,lapply(.SD, head, 1), 
                                              by=.(VAR_ID, POS_NT)]
  
  numeric_cols_dt[,VAR_ID:=nonnumeric_cols_dt[,VAR_ID]]
  numeric_cols_dt[,POS_NT:=nonnumeric_cols_dt[,POS_NT]]
  
  numeric_sd_cols<- names(numeric_cols_dt)
  # Need to explicitly remove the "by" columns, as numeric_sd_cols is evaluated lazily
  numeric_sd_cols<- numeric_sd_cols[!numeric_sd_cols%in%dt_keys]
  
  recomp_numeric_dt<- numeric_cols_dt[,lapply(.SD, agg_fun),
                                      by=.(VAR_ID, POS_NT), 
                                      .SDcols=numeric_sd_cols]
  
  merged_dt<- merge(recomp_numeric_dt, collapse_nonnumeric_dt, by=dt_keys)
  
  merged_dt[,CAF:=(CAO*2)/DP]
  return(merged_dt)
}


# Lack of normalization of features that depend on DP cause lack of generalization to other datasets

#' Centers with the robust median
#'
#' @param x numeric or integer vector
#' @param standardize logical indicating the data should also be standardized after centering.
#' @return numeric vector centered and possibly standardized
robust_center<- function(x, standardize=FALSE){
  centered_x<- x - median(x)
  if(standardize==TRUE){
    centered_x<- centered_x / sd(centered_x)
  }
  return(centered_x)
}


#' Scales numeric and integer columns of a data.table
#'
#' @param in_dt input data.table, can contain both numeric and non-numeric columns
#' @param version character one of v0.2 or v0.3, specifying VariantCaller version
#' @param standardize logical indicating the data should be standardized after centering.
#'
#' @return data.table with numeric and integer columns centered and possibly standardized
scale_numeric_features<- function(in_dt, standardize=FALSE, nonscale_features=VCF_SUMMARY_V0.9_NONSCALE_FEATURES){
  
  dt_copy<- copy(in_dt)
  dt_copy[,`:=`(Sample=as.factor(Sample), 
                POS=as.factor(POS), 
                VAR_ID=as.factor(VAR_ID), 
                POS_NT=as.factor(POS_NT), 
                EXON_ID=as.factor(EXON_ID))]
  
  # Don't scale features that don't explicitly need it
  nonscale_dt<- dt_copy[,..nonscale_features]
  remain_dt<- dt_copy[,-..nonscale_features]
  
  numeric_col_classes<- sapply(remain_dt, class)
  which_numeric<- numeric_col_classes%in%c("integer", "numeric", "single", "double")
  
  numeric_cols_dt<- remain_dt[,which_numeric,with=FALSE]
  nonnumeric_cols_dt<- remain_dt[,!which_numeric,with=FALSE]
  numeric_cols_dt[,Sample:=nonnumeric_cols_dt[,Sample]]
  
  numeric_features<- names(numeric_cols_dt)
  numeric_features<- numeric_features[!numeric_features%in%c("Sample")]
  
  numeric_cols_coerced_dt<- numeric_cols_dt[
    ,lapply(.SD, as.numeric), 
    by=.(Sample), .SDcols=numeric_features]
  
  numeric_cols_scaled_dt<- numeric_cols_coerced_dt[
    ,lapply(.SD, robust_center, standardize), 
    by=.(Sample), .SDcols=numeric_features]
  
  numeric_cols_scaled_dt[,Sample:=NULL]
  recombined_dt<- cbind(nonnumeric_cols_dt, numeric_cols_scaled_dt, nonscale_dt)
  
  recombined_dt[,POS:=as.integer(as.character(POS))]
  recombined_dt[,POS_NT:=as.integer(as.character(POS_NT))]
  
  return(recombined_dt)
}


#' Shifts values in a vector to the max value
#'
#' @param x numeric or integer vector
#' @return values shifted by the max value in x
max_shift<- function(x){
  shifted_x<- x - max(x)
  return(shifted_x)
}


#' Shifts values in a vector to the value of the first element
#'
#' @param x numeric or integer vector
#' @return values shifted by the first value in x
first_shift<- function(x){
  shifted_x<- x - x[1]
  return(shifted_x)
}


#' Gets the range of a numeric or integer vector
#'
#' @param x numeric or integer vector
#' @return range of x
get_range<- function(x){
  sorted_x<- sort(x)
  max_dist<- abs(x[length(x)] - x[1])
  return(max_dist)
}


#' Gets the studentized range of a numeric or integer vector
#'
#' @param x numeric or integer vector
#' @return studentized range of x
get_studentized_range<- function(x){
  sorted_x<- sort(x)
  max_dist<- abs(x[length(x)] - x[1])
  sd_range<- max_dist / sd(x)
  return(sd_range)
}


#' Gets the normalized range of a numeric or integer vector
#'
#' @param x numeric or integer vector
#' @return normalized range of x
get_normed_range<- function(x){
  sorted_x<- sort(x)
  max_dist<- abs(x[length(x)] - x[1])
  norm_range<- max_dist / median(x)
  return(norm_range)
}


#' Gets the standard error
#'
#' @param x numeric or integer vector
#' @return standard error
se<- function(x){
  res<- sd(x)/sqrt(length(x))
  return(res)
}


#' Gets the confidence interval bounds
#'
#' @param vals numeric or integer vector
#' @param min_ci logical which CI bound to return
#' @param alpha numeric signifance level
#' @return numeric CI bound
ci<- function(vals, min_ci=TRUE, alpha=0.05){
  a<- qnorm(1-alpha/2)
  se_res<- se(vals)
  mean_vals<- mean(vals)
  
  if(min_ci){
    ci_res<- mean_vals-a*se_res
  } else{
    ci_res<- mean_vals+a*se_res
  }
  return(ci_res)
}


#' Gets the root mean squared error
#'
#' @param predicted numeric or integer vector predicted values
#' @param truth numeric or integer vector known values
#' @return numeric RMSE
rmse<- function(predicted, truth){
  res<- sqrt(mean((predicted-truth)^2))
  return(res)
}

#' Subtracts magnitude of a numeric vector based on crosstalk percentage estimate
#'
#' @param x numeric or integer vector
#' @param xtalk_prop numeric estimate of barcode crosstalk proportion 
#' @return values corrected to remove contribution of crosstalk
subtract_xtalk<- function(x, xtalk_prop){
  corrected_x<- x - (max(x) * xtalk_prop)
  return(corrected_x)
}


#' Subtracts proportion of frequency potentially caused by barcode crosstalk
#'
#' @param in_dt data.table in vcf.summary.txt format, with MNPs collapsed
#' @param xtalk_prop numeric estimate of barcode crosstalk proportion
#' @return data.table with numeric features corrected for barcode crosstalk
remove_xtalk<- function(in_dt, xtalk_prop=0.014, features_to_correct=VCF_SUMMARY_V0.9_FEATURES_CORRECT){
  
  copy_dt<- copy(in_dt)
  setkey(copy_dt, VAR_ID)
  
  nonfeature_dt<- copy_dt[,-..features_to_correct]
  to_correct_dt<- copy_dt[,..features_to_correct]
  to_correct_dt[,VAR_ID:=nonfeature_dt[,VAR_ID]]
  to_correct_dt[,TYPE:=nonfeature_dt[,TYPE]]
  
  # Find the set of sample-unique IDs
  counts_by_varid<- copy_dt[,.N,by=.(VAR_ID, TYPE)]
  
  uniq_ids<- counts_by_varid[N==1, as.character(unique(VAR_ID))]
  
  noncorrected_dt<- to_correct_dt[VAR_ID%in%uniq_ids,]
  
  corrected_dt<- to_correct_dt[
    !VAR_ID%in%uniq_ids, lapply(.SD, subtract_xtalk, xtalk_prop), 
    by=.(VAR_ID, TYPE), .SDcols=features_to_correct]
  
  feature_dt<- rbind(corrected_dt, noncorrected_dt)
  setkey(feature_dt, VAR_ID)
  feature_dt[,VAR_ID:=NULL]
  feature_dt[,TYPE:=NULL]
  
  combined_dt<- cbind(nonfeature_dt, feature_dt)

  filtered_dt<- combined_dt[CAO>=1,]
  filtered_dt[,CAF:=(CAO*2)/DP]
  
  return(filtered_dt)
}


#' Gets the fraction ranges for each number of fractions present for each VAR_ID
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @return data.table with proportions of each fraction range for each number of fractions observed
#' @details useful in comparison of polysome fraction data to random null distributions
get_ranges_by_nfractions<- function(in_dt){
  
  # First uniquify the input because MNPs are represented by component bps
  uniq_dt<- unique(in_dt[,.(Fraction,VAR_ID)])
  
  # First find the number of fractions each variant ID is in
  fractions_by_varid<- uniq_dt[,.(nfractions=.N), by=.(VAR_ID)]
  
  # Then compute the fraction range for each variant ID
  fractions_by_varid$Fraction_range<- uniq_dt[,get_range(Fraction), by=.(VAR_ID)]$V1
  
  # Now sum the occurences for each [nfractions x ranges]
  nfractions_ranges_totals<- fractions_by_varid[,.N, by=.(nfractions, Fraction_range)]
  
  # The denominator will be the sums for just the nfractions
  nfractions_totals<- fractions_by_varid[,.N,by=.(nfractions)]
  
  # Get the match indices for reassignment of the denominator and assign
  nfractions_ranges_totals_match_indices<- match(nfractions_ranges_totals$nfractions, nfractions_totals$nfractions)
  nfractions_ranges_totals[,nfractions_total:=nfractions_totals[nfractions_ranges_totals_match_indices,N]]
  
  # Finally compute the proportion of each range for each nfractions
  nfractions_ranges_totals[,Proportion_ranges:=N/nfractions_total]
  
  # Add placeholders for ranges that do no exist for nfractions; i is nfractions, j is Fraction_range
  nfractions_ranges_totals[,nfractions.Fraction_range:=paste(nfractions, Fraction_range, sep=".")]
  for(i in 1:9){
    for(j in 0:8){
      combo<- paste(i,j,sep=".")
      if(!(combo%in%nfractions_ranges_totals$nfractions.Fraction_range)){
        nfractions_ranges_totals<- rbind(nfractions_ranges_totals, data.table(
          nfractions=i, Fraction_range=j, N=NA, nfractions_total=NA, Proportion_ranges=0.0, nfractions.Fraction_range=combo))
      }
    }
  }
  setkey(nfractions_ranges_totals, nfractions, Fraction_range)
  return(nfractions_ranges_totals)
}


numeric_median<- function(x){
  res<- as.numeric(median(x))
  return(res)
}


#' Collapses per-bp records into per-variant records
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param key_features character vector of keys to merge on. (Include your other variables).
#' @param agg_fun function to use to aggregate for each level.
#' @return data.table with per-bp statistics collapsed/aggregated
#' @details needed to ensure aggregation of data is not influenced by variant type
collapse_mnps<- function(in_dt, key_features=c("Sample", "VAR_ID"), agg_fun=numeric_median){
  
  copy_dt<- copy(in_dt)
  setkeyv(copy_dt, key_features)
  
  # The following is just for reference
  per_bp_features<- c("POS_NT", "REF_NT", "ALT_NT", "UP_REF_NT", "DOWN_REF_NT")
  
  numeric_col_classes<- sapply(copy_dt, class)
  which_numeric<- numeric_col_classes%in%c("integer", "numeric", "single", "double")
  
  numeric_cols_dt<- copy_dt[,which_numeric,with=FALSE]
  nonnumeric_cols_dt<- copy_dt[,!which_numeric,with=FALSE]
  
  # Add back in the key columns
  for(i in 1:length(key_features)){
    numeric_cols_dt[,key_features[i]:=nonnumeric_cols_dt[,key_features[i],with=FALSE]]
  }
  #numeric_cols_dt[,Sample:=nonnumeric_cols_dt[,Sample]]
  #numeric_cols_dt[,VAR_ID:=nonnumeric_cols_dt[,VAR_ID]]
  
  numeric_features<- names(numeric_cols_dt)
  # numeric_features is evaluated lazily in .SDcols, so explicitly remove the keys
  numeric_features<- numeric_features[
    !numeric_features%in%key_features]
  
  nonnumeric_features<- names(nonnumeric_cols_dt)
  nonnumeric_features<- nonnumeric_features[
    !nonnumeric_features%in%c(key_features)]
  
  # Aggregate numeric features; most features have duplicated values, 
  # but BQs are per-bp features to be aggregated
  numeric_cols_agg_dt<- numeric_cols_dt[
    ,lapply(.SD, agg_fun), 
    by=key_features, 
    .SDcols=numeric_features]
  
  # Similarly, we must collapse the nonnumeric features
  nonnumeric_cols_collapse_dt<- nonnumeric_cols_dt[
    ,lapply(.SD, head, 1), 
    by=key_features, 
    .SDcols=nonnumeric_features]
  
  merged_dt<- merge(nonnumeric_cols_collapse_dt, 
                    numeric_cols_agg_dt, 
                    by=key_features)
  
  return(merged_dt)
}


#' Removes multi-AA change variants
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @return data.table without multi-AA change variants (e.g. p.K247R,p.L248L)
#' @details needed to coerce AAM_AA_POS to integer for plotting
remove_multi_aas<- function(in_dt){
  copy_dt<- copy(in_dt)
  filt_dt<- copy_dt[!grepl(",", AAM_AA_CHANGE),]
  filt_dt[,AAM_AA_POS:=as.integer(AAM_AA_POS)]
  return(filt_dt)
}

#' Gets a list of results for a data.table filtered on increasing thresholds of a filter variable
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param filter_var character of a numeric or integer variable to filter on
#' @param res_var character of a variable to report for each threshold on filter_var
#' @param nthresholds integer number of thresholds for variable
#' @param comparator character of a inequality comparator
#' @return list 
get_count_by_filter_thresh<- function(in_dt, filter_var, res_var, n_thresholds, comparator=">="){
  
  min_val<- min(dt[[filter_var]])
  max_val<- max(dt[[filter_var]])
  thresholds<- seq(min_val, max_val, length.out=n_thresholds)
  
  res_list<- list(mode="list", length=n_thresholds)
  for(i in 1:n_thresholds){
    filter_expr<- paste0(filter_var, comparator, thresholds[i])
    res_list[[i]]<- in_dt[eval(parse(text=filter_expr)), res_var, with=FALSE]
  }
  names(res_list)<- thresholds
  return(res_list)
}


#' Applies a simple AF subtraction approach for removal of error
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @return data.table with AF subtract of the negative applied to other samples
subtract_af<- function(in_dt){
  
  copy_dt<- copy(in_dt)
  neg_dt<- copy_dt[Experiment=="Negative_control", .(VAR_ID, CAF)]
  
  # Merge the two tables so we can easily subtract the negative frequencies via a vectorized operation
  merged_dt<- merge(copy_dt[Experiment!="Negative_control"], neg_dt, by="VAR_ID", all.x=TRUE)
  
  # Set baseline to 0 for variants unique to a polysomal fraction
  merged_dt[is.na(CAF.y), CAF.y:=0.0]

  # Finally subtract the frequencies and remove those variants with negative resultant frequencies
  merged_dt[,CAF:=CAF.x-CAF.y]
  filtered_dt<- merged_dt[CAF>0,]
  filtered_dt[,log10_CAF:=log10(CAF)]
  
  return(filtered_dt)
}


standardize_vector<- function(x){
  res<- (x-mean(x, na.rm=TRUE))/sd(x, na.rm=TRUE)
  return(res)
}


#' Quantifies the ribosome loading score for a variant
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param key_features character vector of keys for grouping prior to RLS calculation
#' @return data.table giving mapping between keys and RLS
#' @details Can Cenik's method which normalizes to input frequency
get_rls<- function(in_dt, key_features=c("VAR_ID"), annot_features=VCF_SUMMARY_V0.9_RLS_ANNOT_FEATURES){
  
  copy_dt<- copy(in_dt)
  
  key_features_no_var_id<- key_features[!key_features=="VAR_ID"]
  
  # The translational activity will be the sum of the 
  # products between fraction and intensity measure
  score_dt<- copy_dt[
    ,.(Normalized_score_CAO=sum(Fraction * NORM_CAO) / sum(NORM_CAO),
       Normalized_score_CAF=sum(Fraction * CAF) / sum(CAF)), 
    by=key_features]
  
  # Could this be a problem if by is an empty list?
  stdized_score_dt<- score_dt[
    ,`:=`(RLS_CAO=standardize_vector(Normalized_score_CAO),
          RLS_CAF=standardize_vector(Normalized_score_CAF))]
  
  # by=key_features_no_var_id]
  
  key_annot_features<- unique(append(annot_features, key_features))
  
  annot_dt<- unique(copy_dt[,key_annot_features, with=FALSE])
  
  norm_merged_annot_dt<- merge(stdized_score_dt, annot_dt, by=key_features, all.x=TRUE)
  
  norm_merged_annot_dt[
    ,AAM_AA_POS2:=as.numeric(sapply(as.character(AAM_AA_POS), summarize_str_list)),
    by=seq_len(nrow(norm_merged_annot_dt))]
  
  return(norm_merged_annot_dt)
}

  
#' Runs goodness of fit tests for individual variant IDs 
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @return data.table with raw goodness of fit p-values appended as new column
get_fraction_intensity_goodness_of_fit<- function(in_dt, intensity_var="CAO"){
  
  copy_dt<- copy(in_dt)
  
  # First define the prior probabilities based on all variants
  
  # TODO: consider AF?
  chisq_priors_dt<- copy_dt[,lapply(.SD, sum), by=.(Fraction), .SDcols=intensity_var]
  chisq_priors<- round(chisq_priors_dt[[intensity_var]])
  chisq_prior_probs<- chisq_priors / sum(chisq_priors)
  
  # Then run goodness of fit tests for each VAR_ID
  counts_by_varid_fraction<- copy_dt[,
                                     lapply(.SD, round), 
                                     by=.(VAR_ID, Fraction), 
                                     .SDcols=intensity_var]
  
  # Use merge to add in the unused Fraction levels
  uniq_varids<- copy_dt[,unique(VAR_ID)]
  len_uniq_varids<- length(uniq_varids)
  uniq_fractions<- copy_dt[,unique(Fraction)]
  all_levels_dt<- data.table(VAR_ID=rep(uniq_varids, each=length(uniq_fractions)), 
                             Fraction=rep(uniq_fractions, times=len_uniq_varids),
                             Prior=rep(chisq_prior_probs, times=len_uniq_varids))
  
  counts_by_varid_fraction_complete<- merge(counts_by_varid_fraction, all_levels_dt, all=TRUE)
  counts_by_varid_fraction_complete[is.na(CAO), CAO:=0]
  
  # Now that we have all VAR_ID and Fraction records, run the chi-sq test
  res_dt<- counts_by_varid_fraction_complete[,.(pvalue=chisq.test(
    x=CAO, p=Prior, simulate.p.value=TRUE, B=500)$p.value), 
    by=.(VAR_ID)]
  
  return(res_dt)
}


#' Reverse complements a sequence
#'
#' @param nt_seq nucleotide sequence, should contain only {A,T,C,G,N}, case insensitive
#' @return character reverse complemented sequence
revcomp<- function(nt_seq){
  
  if(grepl("[^ATCGUNatcgun]", nt_seq)){
    stop("Sequence has invalid characters")
  }
  
  seq_rev<- paste(rev(unlist(strsplit(nt_seq, ""))), collapse="")
  seq_rev_sub<- chartr("ATCGUNatcgun", "TAGCANtagcan", seq_rev)
  return(seq_rev_sub)
}


summarize_str_list<- function(str_list, split_sep=",", summarization_stat="median"){
  split_unlisted<- as.integer(unlist(strsplit(str_list, split_sep)))
  summarized<- get(summarization_stat)(split_unlisted)
  return(summarized)
}


summarize_str_list_codons<- function(str_list, split_sep=",", summarization_stat="median", trna_expr=NULL){
  
  split_unlisted<- unlist(strsplit(str_list, split_sep))
  
  if(!is.null(trna_expr)){
    trna_match<- match(split_unlisted, trna_expr[,Codon])
    split_unlisted<- trna_expr[trna_match, Sum_log2_count]
  }
  
  summarized<- median(split_unlisted, na.rm=TRUE)
  return(summarized)
}


#' lapply-friendly version of %in%
#'
#' @param e_set character vector containing values to search in
#' @param x character to search
#' @return logical whether or not the x was found in e_set
is_in<- function(e_set, x){
  return(x%in%e_set)
}


#' Determines AA decoded by a specific codon
#'
#' @param codon character 3-nt codon
#' @param aa_codons list named list containing codons for each amino acid
#' @return character amino acid for the codon
aa_from_codon<- function(codon, aa_codons=AA_CODONS_LIST){
  aa<- names(aa_codons)[sapply(aa_codons, is_in, codon)]
  return(aa)
}


#' Determines AA class of a specific AA
#'
#' @param aa single letter AA
#' @param aa_classes list named list containing amino acids for each class
#' @return character class of the amino acid
class_from_aa<- function(aa, aa_classes=aa_class_list){
  aa_class<- names(aa_classes)[sapply(aa_classes, is_in, aa)]
  return(aa_class)
}


#' Generates expression entries for wobble codons
#'
#' @param hydrotrnaseq_summarized_dt data.table containing summarized expression values for tRNAs
#' @return data.table original data.table with entries for wobble codons
expand_wobble_pairs<- function(hydrotrnaseq_summarized_dt){
  
  wobble_anticodons<- hydrotrnaseq_summarized_dt[substr(Anticodon, 1, 1)%in%c("G", "T"), unique(Anticodon)]
  
  # For each anticodon with a G or T at the 5' end, there can be one other codon that can pair with it
  n_wobble_anticodons<- length(wobble_anticodons)

  # Initialize the data.table
  wobble_codon_dt<- data.table(Isotype=vector(mode="character", length=n_wobble_anticodons),
                               Anticodon=vector(mode="character", length=n_wobble_anticodons),
                               Codon=vector(mode="character", length=n_wobble_anticodons), 
                               Sum_log2_count=vector(mode="numeric", length=n_wobble_anticodons))
  
  # Iterate over the anticodons that can form wobble pairing, and create entries for wobble codons
  for(i in 1:length(wobble_anticodons)){
    anticodon<- wobble_anticodons[i]
    wobble_bp<- substr(anticodon, 1, 1)
    
    # These wobble pairing rules are the original described by Crick, which are actually conservative
    if(wobble_bp=="G"){
      wobble_anticodon<- paste0("A", substr(anticodon, 2, 3))
    } else if(wobble_bp=="T"){
      wobble_anticodon<- paste0("C", substr(anticodon, 2, 3))
    }
    
    wobble_codon<- revcomp(wobble_anticodon)
    wobble_aa<- names(aa_codons)[sapply(aa_codons, is_in, wobble_codon)]
    
    # Use the tRNA expression values of the canonical anticodon for the wobble codon
    wobble_codon_dt[i,]<- data.table(Isotype=wobble_aa, Anticodon=anticodon, Codon=wobble_codon, 
                                     Sum_log2_count=hydrotrnaseq_summarized_dt[Anticodon==anticodon, Sum_log2_count])
  }
  
  complete_dt<- rbind(hydrotrnaseq_summarized_dt, wobble_codon_dt)
  setkey(complete_dt, Isotype, Anticodon, Codon)
  return(complete_dt)
}


#' Gets the fraction-unique variant IDs
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param negative_fraction integer fraction number giving the cytoplasmic fraction
#' @return character variant IDs
get_uniq_varids<- function(in_dt, negative_fraction=10){
  varid_counts_dt<- in_dt[Fraction!=negative_fraction, .N, by=.(VAR_ID)]
  uniq_varids<- varid_counts_dt[N==1,VAR_ID]
  return(uniq_varids)
}


#' Gets the variant IDs that are found in all fractions
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param negative_fraction integer fraction number giving the cytoplasmic fraction
#' @return character variant IDs
get_complete_varids<- function(in_dt, negative_fraction=10){
  varid_counts_dt<- in_dt[Fraction!=negative_fraction, .N, by=.(VAR_ID)]
  complete_varids<- varid_counts_dt[N==9, VAR_ID]
  return(complete_varids)
}


#' Annotates the number of fractions a variant was found in 
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @return data.table with additional nfractions column
annotate_fraction_number<- function(in_dt){
  copy_dt<- copy(in_dt)
  varid_counts_dt<- copy_dt[,.N, by=.(VAR_ID)]
  varid_match<- copy_dt[,match(VAR_ID, varid_counts_dt[,VAR_ID])]
  copy_dt[,nfractions:=varid_counts_dt[varid_match, N]]
  return(copy_dt)
}


#' Converts human to mouse gene name conventions
#'
#' @param x character vector of human gene names
#' @return character vector converted to lowercase except for first letter
human_to_mouse_genename<- function(x){
  x_split<- strsplit(x, "")[[1]]
  first_char<- toupper(x_split[1])
  all_other_chars<- sapply(x_split[2:nchar(x)], tolower)
  x_formatted<- paste0(c(first_char, all_other_chars), collapse="")
  return(x_formatted)
}


#' Computes the coefficient of variation
#'
#' @param x vector of numeric or integer values
#' @return numeric
get_cv<- function(x){
  mean_x<- mean(x, na.rm=TRUE)
  sd_x<- sd(x, na.rm=TRUE)
  cv_x<- sd_x/mean_x
  return(cv_x)
}


#' Annotates and collapses per-bp records into per-variant records
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param mapping_dt data.table mapping sample name to desired fraction label
#' @param tile_positions data.table with POS and TILE columns, for annotating PCR tiles. 
#' NULL if no tile annotation desired.
#' @param key_features character vector of keys to merge on. (Include your other variables).
#' @return data.table
postprocess_vcf_summary_dt<- function(in_dt, mapping_dt=NULL, tile_positions_dt=NULL, 
                                      key_features=c("Sample", "VAR_ID")){
  copy_dt<- copy(in_dt)
  annot_dt<- annotate_calls(copy_dt, mapping_dt, tile_positions_dt)
  collapse_dt<- collapse_mnps(in_dt=annot_dt, key_features=key_features)
  return(collapse_dt)
}


#' Annotates and collapses per-bp records into per-variant records
#'
#' @param in_dt data.table in vcf.summary.txt format
#' @param key_features character vector of keys to merge on. (Include your other variables).
#' @param integer stepsize: compute proportion between 0 and max coverage with this stepsize.
#' a smaller stepsize returns a more granular profile but takes longer time to compute.
#' @return data.table
waterfall_ecdf<- function(in_dt, key_features=c("Sample"), stepsize=10){
  
  max_cov<- in_dt[,max(Coverage)]
  
  # Modify max_cov slighlty so we can have an appropriate stepsize
  # to split data evenly
  while(max_cov%%stepsize == 0){
    max_cov<- max_cov + 1
  }
  
  # We compute the ECDF then plot values for 0 to max coverage
  ecdf_res_dt<- in_dt[,.(Proportion_greater_than=1-ecdf(Coverage)(seq(0,max_cov,stepsize)),
                         Coverage=seq(0,max_cov,stepsize)), by=key_features]
  return(ecdf_res_dt)
}


#' Random samples from fraction set given nfractions to sample and replicate times
#'
#' @param fractions integer vector of values to sample from, without replacement
#' @param nfractions integer number of fractions to sample
#' @param times integer replication times
#' @return data.table with probabilities for each fraction range
sample_fractions<- function(fractions=seq(1,9), nfractions=2, times=10000){
  res<- replicate(n=times, expr=get_range(sample(fractions, nfractions)))
  res_props<- table(res)/length(res)
  return(as.data.table(res_props))
}


#' Re-computes CAF by averaging CAF over positions in MNPs
#'
#' @param in_dt data.table vcf.summary.txt per-bp calls prior to collapse
#' @return data.table with CAF updated for MNPs
recompute_caf<- function(in_dt){
  copy_dt<- copy(in_dt)
  recomp_dt<- copy_dt[,CAF:=max(CAO/DP), by=.(VAR_ID)]
  return(recomp_dt)
}


#' Compute the proportion of variants in fractions
#'
#' @param in_dt data.table vcf.summary.txt collapsed per-variant calls
#' @return data.table with proportions for each variant
props_of_variants<- function(in_dt){
  
  fractions<- in_dt[,unique(Fraction)]
  
  res1<- vector(mode="numeric", length=length(fractions))
  res2<- vector(mode="numeric", length=length(fractions))
  res3<- vector(mode="numeric", length=length(fractions))
  res4<- vector(mode="numeric", length=length(fractions))
    
  for(i in 1:length(fractions)){
    frac<- fractions[i]
    
    other_var_ids<- in_dt[Fraction!=frac, unique(VAR_ID)]
    num_var_ids<- length(other_var_ids)
    
    res1[i]<- in_dt[Fraction==frac, 
                   sum(unique(VAR_ID)%in%other_var_ids)/num_var_ids]
    
    res2[i]<- in_dt[Fraction==frac, 
                    sum(!unique(VAR_ID)%in%other_var_ids)/.N]
    
    distal_other_var_ids<- in_dt[
      !Fraction%in%c(frac-1,frac,frac+1), 
      unique(VAR_ID)]
    
    res3[i]<- in_dt[Fraction==frac, 
                    sum(unique(VAR_ID)%in%distal_other_var_ids)/.N]
    
   proximal_other_var_ids<- in_dt[
      Fraction%in%c(frac-1,frac+1), 
      unique(VAR_ID)]
    
    res4[i]<- in_dt[Fraction==frac, 
                    sum(unique(VAR_ID)%in%proximal_other_var_ids)/.N]
    
  }
  res_dt<- data.table(Fraction=fractions, 
                      Proportion_others_all=res1,
                      Proportion_in_distal_fractions=res3,
                      Proportion_in_proximal_fractions=res4,
                      Proportion_unique=res2)
  
  return(res_dt)
}


get_max_fraction<- function(x, y){
  max_x<- which.max(x)
  select_y<- y[max_x]
  return(select_y)
}


get_min_fraction<- function(x, y){
  min_x<- which.min(x)
  select_y<- y[min_x]
  return(select_y)
}


get_last_fraction_median<- function(x, y, n=2){
  ordered_x<- order(x, decreasing=TRUE)
  y_sorted<- y[ordered_x]
  y_len<- length(y)
  last_n<- y_sorted[(y_len-n+1):y_len]
  res<- median(last_n)
  return(res)
}


z_trans<- function(x){
  z<- (x -  mean(x)) / sd(x)
  return(z)
}


robust_z<- function(x){
  rz<- (x - median(x)) / mad(x)
  return(rz)
}


#' Coverts long to short AA formats
#'
#' @param aa_change character HGVS amino acid change, e.g. p.Ala41Thr
convert_aa_notation<- function(aa_change){
  
  aa_change_strip<- strsplit(as.character(aa_change), ".", fixed=T)
  
  if(length(aa_change_strip[[1]])==1){
    aa_change_strip<- aa_change
  } else{
    aa_change_strip<- sapply(aa_change_strip, "[", 2)
  }
  
  pos<- gsub(pattern="[[:alpha:]]|[[:punct:]]", replacement="", aa_change_strip)
  
  aa_change_no_int<- gsub(pattern="[[:digit:]]", replacement=":", aa_change_strip)
  
  aa_change_no_int_split<- unlist(strsplit(aa_change_no_int, ":+"))
  
  final_res<- c()
  for(e in 1:length(aa_change_no_int_split)){
    
    if(e==2){
      final_res<- append(final_res, pos)
      
      if(grepl("[[:punct:]]", aa_change_no_int_split[e])){
        match_res<- names(aa_map)[which(aa_change_no_int_split[1]==aa_map)]
        final_res<- append(final_res, match_res)
        next
      }
    }
    match_res<- names(aa_map)[which(aa_change_no_int_split[e]==aa_map)]
    final_res<- append(final_res, match_res)
  }
  
  final_res<- paste0(c("p.",final_res), collapse="")
  return(final_res)
}

